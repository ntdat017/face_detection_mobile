{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Optimizing Neural Network before Quantization:\n",
      "Fused 245->246\n",
      "Fused 248->249\n",
      "Fused 251->252\n",
      "Fused 254->255\n",
      "Fused 257->258\n",
      "Fused 260->261\n",
      "Fused 263->264\n",
      "Fused 266->267\n",
      "Fused 269->270\n",
      "Fused 272->273\n",
      "Fused 275->276\n",
      "Fused 278->279\n",
      "Fused 281->282\n",
      "Fused 284->285\n",
      "Fused 286->287\n",
      "Fused 289->290\n",
      "Fused 291->292\n",
      "Fused 293->294\n",
      "Fused 296->297\n",
      "Fused 298->299\n",
      "Fused 300->301\n",
      "Fused 303->304\n",
      "Fused 306->307\n",
      "Fused 309->310\n",
      "Fused 311->312\n",
      "Fused 343->344\n",
      "Fused 346->347\n",
      "Fused 349->350\n",
      "Fused 352->353\n",
      "Fused 355->356\n",
      "Fused 358->359\n",
      "Fused 389->390\n",
      "Fused 392->393\n",
      "Fused 395->396\n",
      "Fused 398->399\n",
      "Finished optimizing network. Quantizing neural network..\n",
      "Quantizing layer 245\n",
      "Quantizing layer 248\n",
      "Quantizing layer 251\n",
      "Quantizing layer 254\n",
      "Quantizing layer 257\n",
      "Quantizing layer 260\n",
      "Quantizing layer 263\n",
      "Quantizing layer 266\n",
      "Quantizing layer 269\n",
      "Quantizing layer 272\n",
      "Quantizing layer 275\n",
      "Quantizing layer 278\n",
      "Quantizing layer 281\n",
      "Quantizing layer 284\n",
      "Quantizing layer 286\n",
      "Quantizing layer 289\n",
      "Quantizing layer 291\n",
      "Quantizing layer 293\n",
      "Quantizing layer 296\n",
      "Quantizing layer 298\n",
      "Quantizing layer 300\n",
      "Quantizing layer 303\n",
      "Quantizing layer 306\n",
      "Quantizing layer 309\n",
      "Quantizing layer 311\n",
      "Quantizing layer 315\n",
      "Quantizing layer 317\n",
      "Quantizing layer 329\n",
      "Quantizing layer 331\n",
      "Quantizing layer 343\n",
      "Quantizing layer 346\n",
      "Quantizing layer 349\n",
      "Quantizing layer 352\n",
      "Quantizing layer 355\n",
      "Quantizing layer 358\n",
      "Quantizing layer 361\n",
      "Quantizing layer 363\n",
      "Quantizing layer 375\n",
      "Quantizing layer 377\n",
      "Quantizing layer 389\n",
      "Quantizing layer 392\n",
      "Quantizing layer 395\n",
      "Quantizing layer 398\n",
      "Quantizing layer 401\n",
      "Quantizing layer 403\n",
      "Quantizing layer 415\n",
      "Quantizing layer 417\n",
      "Quantizing layer 429\n",
      "Quantizing layer 431\n",
      "Quantizing layer 433\n",
      "Quantizing layer 435\n",
      "Quantizing layer 447\n"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Convert from ONNX to Core ML\n",
    "def onnx2coreml(model_path, is_quanlized=False, nbit=8):\n",
    "    model = coremltools.converters.onnx.convert(model=model_path, minimum_ios_deployment_target='13')\n",
    "\n",
    "    if is_quanlized == True:\n",
    "        model = coremltools.models.neural_network.quantization_utils.quantize_weights(model, nbit)\n",
    "\n",
    "#     model.save('rfb_320_quanlized.mlmodel')\n",
    "    return model\n",
    "\n",
    "model = coremltools.models.MLModel('rfb_320.mlmodel')\n",
    "quanlized_model = coremltools.models.neural_network.quantization_utils.quantize_weights(model, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08123016357421875\n",
      "0.018069028854370117\n",
      "0.017199039459228516\n",
      "0.017827987670898438\n",
      "0.016321182250976562\n",
      "0.017933130264282227\n",
      "0.01589822769165039\n",
      "0.01651287078857422\n",
      "0.015883922576904297\n",
      "0.016638994216918945\n",
      "0.01576399803161621\n",
      "0.01570296287536621\n",
      "0.018909931182861328\n",
      "0.015386104583740234\n",
      "0.016988277435302734\n",
      "0.01711106300354004\n",
      "0.01595592498779297\n",
      "0.015823841094970703\n",
      "0.017114877700805664\n",
      "0.017115116119384766\n",
      "0.016005992889404297\n",
      "0.017381906509399414\n",
      "0.01732802391052246\n",
      "0.01739501953125\n",
      "0.017396926879882812\n",
      "0.01701974868774414\n",
      "0.016824960708618164\n",
      "0.017627954483032227\n",
      "0.01702880859375\n",
      "0.016412973403930664\n",
      "0.01728081703186035\n",
      "0.017382144927978516\n",
      "0.017338991165161133\n",
      "0.01685500144958496\n",
      "0.01619577407836914\n",
      "0.017386913299560547\n",
      "0.017576932907104492\n",
      "0.01676797866821289\n",
      "0.017538785934448242\n",
      "0.017273664474487305\n",
      "0.016950130462646484\n",
      "0.016909122467041016\n",
      "0.016768932342529297\n",
      "0.017173051834106445\n",
      "0.016785860061645508\n",
      "0.01602625846862793\n",
      "0.015527963638305664\n",
      "0.01695084571838379\n",
      "0.017117977142333984\n",
      "0.017189979553222656\n",
      "0.016582727432250977\n",
      "0.01685786247253418\n",
      "0.016889095306396484\n",
      "0.017146825790405273\n",
      "0.01704692840576172\n",
      "0.016644716262817383\n",
      "0.016585826873779297\n",
      "0.01626873016357422\n",
      "0.016222000122070312\n",
      "0.016620874404907227\n",
      "0.01622295379638672\n",
      "0.016402244567871094\n",
      "0.016895055770874023\n",
      "0.016516923904418945\n",
      "0.016292810440063477\n",
      "0.01636815071105957\n",
      "0.016065120697021484\n",
      "0.016479015350341797\n",
      "0.01589798927307129\n",
      "0.016443729400634766\n",
      "0.01618194580078125\n",
      "0.016373634338378906\n",
      "0.015768051147460938\n",
      "0.015903949737548828\n",
      "0.016301631927490234\n",
      "0.01587200164794922\n",
      "0.016409635543823242\n",
      "0.016047954559326172\n",
      "0.01640605926513672\n",
      "0.0161287784576416\n",
      "0.01673102378845215\n",
      "0.017251014709472656\n",
      "0.01666092872619629\n",
      "0.016138076782226562\n",
      "0.016145944595336914\n",
      "0.017058134078979492\n",
      "0.016790151596069336\n",
      "0.01692509651184082\n",
      "0.01632404327392578\n",
      "0.015836000442504883\n",
      "0.016980886459350586\n",
      "0.016872882843017578\n",
      "0.017149925231933594\n",
      "0.017139911651611328\n",
      "0.0170290470123291\n",
      "0.016286134719848633\n",
      "0.017150163650512695\n",
      "0.016570091247558594\n",
      "0.01600790023803711\n",
      "0.016011953353881836\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('1.jpg')\n",
    "\n",
    "image = image.resize((320, 240))\n",
    "image = np.array(image).astype(np.float32)\n",
    "image = image / 255.\n",
    "\n",
    "image = image.transpose(2, 0, 1)\n",
    "image = image[np.newaxis, :]\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    tt = time.time()\n",
    "    pred = quanlized_model.predict({'input': image})\n",
    "    print(time.time() - tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': array([[[ 0.00601196,  0.00732422,  0.02182007,  0.03399658],\n",
       "         [-0.00198364, -0.00585938,  0.03741455,  0.05258179],\n",
       "         [-0.01075745, -0.01722717,  0.04936218,  0.06816101],\n",
       "         ...,\n",
       "         [ 0.7261963 ,  0.61572266,  1.05896   ,  1.1049805 ],\n",
       "         [ 0.64660645,  0.48364258,  1.1414795 ,  1.2233887 ],\n",
       "         [ 0.5593262 ,  0.3713379 ,  1.2062988 ,  1.2751465 ]]],\n",
       "       dtype=float32),\n",
       " 'scores': array([[[0.9305214 , 0.06947859],\n",
       "         [0.93355215, 0.06644794],\n",
       "         [0.9347534 , 0.06524657],\n",
       "         ...,\n",
       "         [0.93505055, 0.0649494 ],\n",
       "         [0.93941504, 0.06058494],\n",
       "         [0.9494823 , 0.05051767]]], dtype=float32)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def vis(image, bboxes, scores):\n",
    "    image_vis = image.copy()\n",
    "    w, h = 240, 320\n",
    "    indexs = \n",
    "    for bbox, score in zip(bboxes, scores):\n",
    "        \n",
    "        image_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred['scores'][0][:, 1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quanlized_model.save('quanlized_rfb_320.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection_mobile",
   "language": "python",
   "name": "face_detection_mobile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
